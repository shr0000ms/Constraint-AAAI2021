{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"XLNet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"30aefc12abef46618ff230a54c15c0a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e99d966e274340f7a2e218dbd410d18c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bd0698c87738433d9c1deaa70e53e098","IPY_MODEL_a8129918744544ad896e8d798212f418"]}},"e99d966e274340f7a2e218dbd410d18c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd0698c87738433d9c1deaa70e53e098":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c9ae02e650724988994b75bb59e43a11","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":798011,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":798011,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1d28490adbc453db23c29727cdd3e32"}},"a8129918744544ad896e8d798212f418":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_04c108e986434fa5bbcc4ac7b6bf656b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 798k/798k [00:00&lt;00:00, 1.16MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0357c743f64b4cf28b93d834f715bd7f"}},"c9ae02e650724988994b75bb59e43a11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e1d28490adbc453db23c29727cdd3e32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04c108e986434fa5bbcc4ac7b6bf656b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0357c743f64b4cf28b93d834f715bd7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e02f123c3684a959a407c3b3bd4b179":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_46b375eff350402ebdcb4fc7eb3a8d52","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8977d7e31d5e4d528a60ebf954e4cc16","IPY_MODEL_d30f4cd21d69464a9c90dc31a1cae038"]}},"46b375eff350402ebdcb4fc7eb3a8d52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8977d7e31d5e4d528a60ebf954e4cc16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0f61e96e316d4fadb598946b3a4c58b0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":760,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":760,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2d8ead9cfd3945b782168fcd81ac8841"}},"d30f4cd21d69464a9c90dc31a1cae038":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_00252c8a03ae421d8904968a576098bd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 760/760 [00:13&lt;00:00, 58.2B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f9df415ff9e448cfb2b19fe42dac3a71"}},"0f61e96e316d4fadb598946b3a4c58b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2d8ead9cfd3945b782168fcd81ac8841":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00252c8a03ae421d8904968a576098bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f9df415ff9e448cfb2b19fe42dac3a71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27adee1636c64bb6af3419595fa6b7f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_499e7659e24b433ba6f33eefaed268fa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7cb23b05ad85470f997fd7b08393bd8e","IPY_MODEL_35352b9f46bc4fc0a78485582f2d22c2"]}},"499e7659e24b433ba6f33eefaed268fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7cb23b05ad85470f997fd7b08393bd8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5e52758ef1f34329a888b8c555c8e8b3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":467042463,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":467042463,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5382c0515e9647ac961ef3f223d96e74"}},"35352b9f46bc4fc0a78485582f2d22c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e8b0979cccf64ce187f51f8e738054d0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 467M/467M [00:12&lt;00:00, 38.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7cba54fd9237482286c16951a402fd42"}},"5e52758ef1f34329a888b8c555c8e8b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5382c0515e9647ac961ef3f223d96e74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8b0979cccf64ce187f51f8e738054d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7cba54fd9237482286c16951a402fd42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cHa-AZdOfd8g","executionInfo":{"status":"ok","timestamp":1615990889435,"user_tz":-330,"elapsed":9151,"user":{"displayName":"Dipyaman Sanyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibg6GPyyxPdf6KuGOXtXaI61e0daEKh1x84uvoPg=s64","userId":"15612698974928772053"}},"outputId":"b977e5f3-50f0-4ba3-a51f-8b5599c5915b"},"source":["import tensorflow as tf\r\n","\r\n","device_name = tf.test.gpu_device_name()\r\n","if device_name != '/device:GPU:0':\r\n","  raise SystemError('GPU device not found')\r\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gFpSj8vPj5ca","executionInfo":{"status":"ok","timestamp":1615990903337,"user_tz":-330,"elapsed":10105,"user":{"displayName":"Dipyaman Sanyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibg6GPyyxPdf6KuGOXtXaI61e0daEKh1x84uvoPg=s64","userId":"15612698974928772053"}},"outputId":"c43e2a17-8865-43ac-ae46-ac02895fac44"},"source":["#!pip install pytorch-transformers\r\n","!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/d8/5144b0712f7f82229a8da5983a8fbb8d30cec5fbd5f8d12ffe1854dcea67/transformers-4.4.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 5.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 37.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 35.6MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=a1bca37e35a019350d648ef7800858ef15df326feb88f7ac4360e2ce6a79bb8c\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkdI-PQTkLyT","executionInfo":{"status":"ok","timestamp":1615990936434,"user_tz":-330,"elapsed":28711,"user":{"displayName":"Dipyaman Sanyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibg6GPyyxPdf6KuGOXtXaI61e0daEKh1x84uvoPg=s64","userId":"15612698974928772053"}},"outputId":"6c8dabd7-177f-431a-cebc-af9db148bc9f"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yWajicQBkgas","executionInfo":{"status":"ok","timestamp":1615990949392,"user_tz":-330,"elapsed":7063,"user":{"displayName":"Dipyaman Sanyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibg6GPyyxPdf6KuGOXtXaI61e0daEKh1x84uvoPg=s64","userId":"15612698974928772053"}}},"source":["\r\n","import torch\r\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","\r\n","from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\r\n","from transformers import AdamW\r\n","\r\n","from tqdm import tqdm, trange\r\n","import pandas as pd\r\n","import io\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"3ruvsk78k0N6","executionInfo":{"status":"ok","timestamp":1615991200310,"user_tz":-330,"elapsed":1403,"user":{"displayName":"Dipyaman Sanyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibg6GPyyxPdf6KuGOXtXaI61e0daEKh1x84uvoPg=s64","userId":"15612698974928772053"}},"outputId":"f9f05a25-f6ae-48b2-d1d4-5d1c8e20f948"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n","n_gpu = torch.cuda.device_count()\r\n","torch.cuda.get_device_name(0)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla K80'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"UnL6uIp4k7fU","executionInfo":{"status":"ok","timestamp":1615991211057,"user_tz":-330,"elapsed":1918,"user":{"displayName":"Dipyaman Sanyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibg6GPyyxPdf6KuGOXtXaI61e0daEKh1x84uvoPg=s64","userId":"15612698974928772053"}},"outputId":"e9c92d74-7a38-4230-eded-0cd2689e97d5"},"source":["names = ['Tweet', 'Label']\r\n","df = pd.read_csv('/content/drive/MyDrive/Fake News datasets/train.csv', sep=',', names=names, header=0)\r\n","df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The CDC current report 99031 deaths. In genera...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>State report 1121 death small rise last Tuesda...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Polit Correct Woman ( Almost ) Uses Pandem as ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>India Fight Corona : We have 1524 C O V D test...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Popul state can generat larg case count but if...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Tweet  Label\n","0  The CDC current report 99031 deaths. In genera...      0\n","1  State report 1121 death small rise last Tuesda...      0\n","2  Polit Correct Woman ( Almost ) Uses Pandem as ...      1\n","3  India Fight Corona : We have 1524 C O V D test...      0\n","4  Popul state can generat larg case count but if...      0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"-LIk4Ehcl74t","executionInfo":{"status":"error","timestamp":1615994304839,"user_tz":-330,"elapsed":899,"user":{"displayName":"Dipyaman Sanyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibg6GPyyxPdf6KuGOXtXaI61e0daEKh1x84uvoPg=s64","userId":"15612698974928772053"}},"outputId":"19c150c5-50e9-4389-f6ac-b68d4d9a9bb5"},"source":["df.shape"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-633337079cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"code","metadata":{"id":"w3rgTRcql_h5"},"source":["sentences = df['Tweet'].values\r\n","sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]\r\n","labels = df['Label'].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"6TaYKDxumb22","executionInfo":{"status":"ok","timestamp":1615640349398,"user_tz":-330,"elapsed":1103,"user":{"displayName":"Dipyaman Sanyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibg6GPyyxPdf6KuGOXtXaI61e0daEKh1x84uvoPg=s64","userId":"15612698974928772053"}},"outputId":"2e694451-2462-4e4b-d6c8-b0e41264bb87"},"source":["sentences[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'The CDC current report 99031 deaths. In general discrep death count differ sourc are small and explicable. The death toll stand rough 100000 peopl today . [SEP] [CLS]'"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119,"referenced_widgets":["30aefc12abef46618ff230a54c15c0a0","e99d966e274340f7a2e218dbd410d18c","bd0698c87738433d9c1deaa70e53e098","a8129918744544ad896e8d798212f418","c9ae02e650724988994b75bb59e43a11","e1d28490adbc453db23c29727cdd3e32","04c108e986434fa5bbcc4ac7b6bf656b","0357c743f64b4cf28b93d834f715bd7f"]},"id":"XLy2xLyIme3G","executionInfo":{"status":"ok","timestamp":1615640354445,"user_tz":-330,"elapsed":3878,"user":{"displayName":"Dipyaman Sanyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibg6GPyyxPdf6KuGOXtXaI61e0daEKh1x84uvoPg=s64","userId":"15612698974928772053"}},"outputId":"f9c81f66-c8dc-4040-d140-b233f69fde6d"},"source":["tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\r\n","\r\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n","print (\"Tokenize the first sentence:\")\r\n","print (tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30aefc12abef46618ff230a54c15c0a0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Tokenize the first sentence:\n","['▁the', '▁c', 'd', 'c', '▁current', '▁report', '▁9', '90', '31', '▁deaths', '.', '▁in', '▁general', '▁disc', 're', 'p', '▁death', '▁count', '▁differ', '▁sour', 'c', '▁are', '▁small', '▁and', '▁', 'exp', 'lic', 'able', '.', '▁the', '▁death', '▁toll', '▁stand', '▁rough', '▁100', '000', '▁', 'pe', 'op', 'l', '▁today', '▁', '.', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SB88fi6zmltH"},"source":["MAX_LEN = 128\r\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"45hcVdHymxVK"},"source":["# Create attention masks\r\n","attention_masks = []\r\n","\r\n","# Create a mask of 1s for each token followed by 0s for padding\r\n","for seq in input_ids:\r\n","  seq_mask = [float(i>0) for i in seq]\r\n","  attention_masks.append(seq_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O2F2qdYfm0rx"},"source":["train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \r\n","                                                            random_state=56, test_size=0.2)\r\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\r\n","                                             random_state=56, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgbmB4kqooP4"},"source":["train_inputs = torch.tensor(train_inputs)\r\n","validation_inputs = torch.tensor(validation_inputs)\r\n","train_labels = torch.tensor(train_labels)\r\n","validation_labels = torch.tensor(validation_labels)\r\n","train_masks = torch.tensor(train_masks)\r\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dn9BwKXfoqgi"},"source":["batch_size = 32\r\n","\r\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n","train_sampler = RandomSampler(train_data)\r\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n","\r\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n","validation_sampler = SequentialSampler(validation_data)\r\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8e02f123c3684a959a407c3b3bd4b179","46b375eff350402ebdcb4fc7eb3a8d52","8977d7e31d5e4d528a60ebf954e4cc16","d30f4cd21d69464a9c90dc31a1cae038","0f61e96e316d4fadb598946b3a4c58b0","2d8ead9cfd3945b782168fcd81ac8841","00252c8a03ae421d8904968a576098bd","f9df415ff9e448cfb2b19fe42dac3a71","27adee1636c64bb6af3419595fa6b7f5","499e7659e24b433ba6f33eefaed268fa","7cb23b05ad85470f997fd7b08393bd8e","35352b9f46bc4fc0a78485582f2d22c2","5e52758ef1f34329a888b8c555c8e8b3","5382c0515e9647ac961ef3f223d96e74","e8b0979cccf64ce187f51f8e738054d0","7cba54fd9237482286c16951a402fd42"]},"id":"7PcteKlWouuj","executionInfo":{"status":"ok","timestamp":1615640401115,"user_tz":-330,"elapsed":27142,"user":{"displayName":"Dipyaman Sanyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibg6GPyyxPdf6KuGOXtXaI61e0daEKh1x84uvoPg=s64","userId":"15612698974928772053"}},"outputId":"b25e4fbd-f1eb-4059-865c-fcc07aa1359c"},"source":["model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=2)\r\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e02f123c3684a959a407c3b3bd4b179","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27adee1636c64bb6af3419595fa6b7f5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["XLNetForSequenceClassification(\n","  (transformer): XLNetModel(\n","    (word_embedding): Embedding(32000, 768)\n","    (layer): ModuleList(\n","      (0): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (6): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (7): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (8): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (9): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (10): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (11): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (sequence_summary): SequenceSummary(\n","    (summary): Linear(in_features=768, out_features=768, bias=True)\n","    (first_dropout): Identity()\n","    (last_dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"VGMDv-6Woyhe"},"source":["\r\n","param_optimizer = list(model.named_parameters())\r\n","no_decay = ['bias', 'gamma', 'beta']\r\n","optimizer_grouped_parameters = [\r\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\r\n","     'weight_decay_rate': 0.01},\r\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\r\n","     'weight_decay_rate': 0.0}\r\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BWhjKtL8rcpE","colab":{"base_uri":"https://localhost:8080/","height":181},"executionInfo":{"status":"error","timestamp":1615990357431,"user_tz":-330,"elapsed":1386,"user":{"displayName":"Aritra Chakraborty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiET2Z7tP6nrb45Mh9YAoYs9Anssr1910Z05SwgJw=s64","userId":"03130551807147804244"}},"outputId":"144c0866-b2ee-4517-9b91-c6daed64df8c"},"source":["optimizer = AdamW(optimizer_grouped_parameters,\r\n","                     lr=2e-5)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-876669627edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m optimizer = AdamW(optimizer_grouped_parameters,\n\u001b[0m\u001b[1;32m      2\u001b[0m                      lr=2e-5)\n","\u001b[0;31mNameError\u001b[0m: name 'AdamW' is not defined"]}]},{"cell_type":"code","metadata":{"id":"NOrDQsvCtpwj"},"source":["def flat_accuracy(preds, labels):\r\n","    pred_flat = np.argmax(preds, axis=1).flatten()\r\n","    labels_flat = labels.flatten()\r\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9NEQJE4Mrfie"},"source":["# Store our loss and accuracy for plotting\r\n","train_loss_set = []\r\n","\r\n","# Number of training epochs (authors recommend between 2 and 4)\r\n","epochs = 4\r\n","\r\n","# trange is a tqdm wrapper around the normal python range\r\n","for _ in trange(epochs, desc=\"Epoch\"):\r\n","  \r\n","  \r\n","  # Training\r\n","  \r\n","  # Set our model to training mode (as opposed to evaluation mode)\r\n","  model.train()\r\n","  \r\n","  # Tracking variables\r\n","  tr_loss = 0\r\n","  nb_tr_examples, nb_tr_steps = 0, 0\r\n","  \r\n","  # Train the data for one epoch\r\n","  for step, batch in enumerate(train_dataloader):\r\n","    # Add batch to GPU\r\n","    batch = tuple(t.to(device) for t in batch)\r\n","    # Unpack the inputs from our dataloader\r\n","    b_input_ids, b_input_mask, b_labels = batch\r\n","    # Clear out the gradients (by default they accumulate)\r\n","    optimizer.zero_grad()\r\n","    # Forward pass\r\n","    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\r\n","    loss = outputs[0]\r\n","    logits = outputs[1]\r\n","    train_loss_set.append(loss.item())    \r\n","    # Backward pass\r\n","    loss.backward()\r\n","    # Update parameters and take a step using the computed gradient\r\n","    optimizer.step()\r\n","    \r\n","    \r\n","    # Update tracking variables\r\n","    tr_loss += loss.item()\r\n","    nb_tr_examples += b_input_ids.size(0)\r\n","    nb_tr_steps += 1\r\n","\r\n","  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\r\n","    \r\n","    \r\n","  # Validation\r\n","\r\n","  # Put model in evaluation mode to evaluate loss on the validation set\r\n","  model.eval()\r\n","\r\n","  # Tracking variables \r\n","  eval_loss, eval_accuracy = 0, 0\r\n","  nb_eval_steps, nb_eval_examples = 0, 0\r\n","\r\n","  # Evaluate data for one epoch\r\n","  for batch in validation_dataloader:\r\n","    # Add batch to GPU\r\n","    batch = tuple(t.to(device) for t in batch)\r\n","    # Unpack the inputs from our dataloader\r\n","    b_input_ids, b_input_mask, b_labels = batch\r\n","    # Telling the model not to compute or store gradients, saving memory and speeding up validation\r\n","    with torch.no_grad():\r\n","      # Forward pass, calculate logit predictions\r\n","      output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\r\n","      logits = output[0]\r\n","    \r\n","    # Move logits and labels to CPU\r\n","    logits = logits.detach().cpu().numpy()\r\n","    label_ids = b_labels.to('cpu').numpy()\r\n","\r\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n","    \r\n","    eval_accuracy += tmp_eval_accuracy\r\n","    nb_eval_steps += 1\r\n","\r\n","  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWEzRI3usP7p"},"source":[""],"execution_count":null,"outputs":[]}]}